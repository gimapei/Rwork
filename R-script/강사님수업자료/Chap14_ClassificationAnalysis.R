# Chap14_ClassificationAnalysis

###################################################
# 분류분석(ClassificationAnalysis) = Decision Tree
###################################################
# - 종속변수(y변수) 존재
# - 종속변수 : 예측에 Focus을 두는 변수
# - 비모수 검정 : 선형성, 정규성, 등분산성 가정 필요없음
# - 단점 : 유의수준 판단 기준 없음(추론 기능 없음)
# - 규칙(Rule)을 기반으로 의사결정트리 생성


###########################################
# party 패키지를 적용한 분류분석
###########################################

# part패키지 설치
install.packages("party")
library(party) # ctree() 제공
data(iris)
summary(iris)


#----------------<<실습1>>-------------------------------
# R에서 기본으로 제공되는 airquality 데이터 셋을 이용하기 위해서 
# - Temp(온도)에 영향을 미치는 변수를 알아보기 -  
# airquality 데이터 셋 153개의 관측치와 6개의 변수로 구성되어 있으며
# New York의 대기에 관한 질을 측정한 데이터 셋이다. 
# 주요 변수로는 Ozone(오존수치), Solar.R(태양광), Wind(바람), 
# Temp(온도), Month(측정 월), Day(측정 날짜) 등이 있다.
#--------------------------------------------------------

# airquality 데이터 셋 로딩
library(datasets)
str(airquality)

# formula 생성 : y ~ x1 + x2 + x3
formula <-  Temp ~ Solar.R +  Wind + Ozone

# 분류모델 생성 : formula를 이용하여 분류모델 생성 
air_ctree <- ctree(formula, data=airquality)
air_ctree

plot(air_ctree)

# <해설> 온도에 가장 큰 영향을 미치는 첫 번째 영향 변수는 오존수치(Ozone)이고, 
# 두 번째 영향 변수는 바람(Wind)으로 나타난다. 

#----------------<<실습2>>-------------------------------
#4개변수(Sepal Length,Sepal Width,Petal Length,Petal Width) 
# 값에 따라서 꽃의 종류(Species)가 분류되는 분석 과정
#--------------------------------------------------------

#단계1 : 학습데이터와 검증데이터 샘플링
# set.seed(1234) # 메모리에 시드값 적용 - 동일값 생성 
result <- sample(2, nrow(iris),replace=T, prob=c(0.7,0.3)) 

table(result) # 7:3비율 데이터 생성
train <- iris[result==1,] 
test <- iris[result==2,]  

names(iris)
# 단계2 : formula 생성 
#  -> 형식) 변수 <- 종속변수 ~ 독립변수
formula <- Species ~ Sepal.Length+Sepal.Width+Petal.Length+Petal.Width 


#단계3 : 학습데이터 이용 분류모델 생성(ctree()함수 이용)
iris_ctree <- ctree(formula, data=train) # 학습데이터로 분류모델(tree) 생성
iris_ctree # Petal.Length,Petal.Width 중요변수

#단계4 : 분류모델 플로팅
# plot() 이용 - 의사결정 트리로 결과 플로팅
plot(iris_ctree, type="simple") 
plot(iris_ctree) # 의사결정트리 해석


# 단계5 : 검정 데이터에 분류모델 적용(분류모델 검정)
iris_ctree2 <- ctree(formula, data=test) 
iris_ctree2

# 1) 의사결정 트리 플로팅
plot(iris_ctree2)

# 2) 분류모델 예측 - predict(모델(train), test)
testpred <- predict(iris_ctree, test) # 검정 데이터 적용
testpred

# 3) 분류모델 성능 평가 
nrow(test) # 43
table(testpred,test$Species) # 3개 영역으로 분류 
#testpred     setosa versicolor virginica
#setosa         14          0         0  <- missing = 0
#versicolor      0         15         1  <- missing = 1
#virginica       0          1        12  <- missing = 1

# 적중력 = (14+15+12)/nrow(test)
(14+15+12)/nrow(test) # 0.9534884 - 95%

# <해설> 생성된 분류모델을 학습 데이터와 검정 데이터에 각각 적용하여 
# 분석된 결과를 살펴보면 꽃의 종류를 분류하는데 있어서 가장 중요한 변수는 
# Petal.Length(꽃잎길이)와 Petal.Width(꽃잎너비)로 모두 동일하게 나타났다. 
# 위 결과는 표본에 의해서 추출된 데이터이기 때문에 실행결과는 다를 수 있다. 

#----------------<<실습3>>-------------------------------
# 다이아몬드의 가격(price)에 미치는 영향변수 보기
# ggplot2 패키지에서 제공되는 diamonds 데이터 셋을 대상으로 
# 반응변수를 price로 지정하고, 설명변수를 carat, cut, color, 
# depth 지정하여 분류결과를 확인한다.
#--------------------------------------------------------

# 패키지 설치 및 로딩
install.packages("ggplot2")
library(ggplot2)
data(diamonds) # ggplot2에서 제공되는 데이터 셋 로딩

# 검정 데이터 만들기
# diamonds 데이터 셋의 전체 관측치는 53,860으로 구성되어 있기 
# 때문에 그 중 50개만 표본으로 추출하여 검정 데이터를 생성한다. 
# 관측치가 지나치게 많은 경우에는 효율성과 해석력이 떨질 수 있다.

t <- sample(1:nrow(diamonds), 50)
test <- diamonds[t, ] # 50개 관측치만 표본으로 추출
dim(test) # [1] 50 10
test # 검정 데이터

# formula 작성과 분류분석
# 반응변수를 price로 지정하고, 설명변수를 carat, cut, color, depth로 
# 지정하여 분류분석을 위한 식으로 작성하고 분류분석을 수행 한다.

formula <- price ~ carat +  cut + color + depth # 분류분석 식 작성
diamonds_ctree <- ctree(formula, data=test) # 검정 데이터로 분류분석 
diamonds_ctree

# <해설> diamonds 데이터 셋에서 추출된 50개의 검정 데이터를 대상으로 
# 분류분석 한 결과에서 다이아몬드의 가격(prince)은 설명변수
# 4개 중에서 다이아몬드의 크기(carat)에 의해서 분류되는 것을 확인할 수 있다. 

# 분류분석 결과 시각화
range(test$carat) # [1] 0.26 2.08
plot(diamonds_ctree)


#----------------<<실습4>>-------------------------------
# AdultUCI 데이터 셋을 이용한 분류분석
# AdultUCI 데이터 셋에 관한 설명
# arules패키지에서 제공되는 데이터 셋으로 성인을 대상으로 
# 인구 소득에 관한 설문조사 데이터를 포함하고 있다. 
# 전체 48,842개의 관측치와 15개 변수로 구성되어 있다. 
# 주요 변수 : age(나이),workclass(직업:4개),education(교육수준:16개),
# occupation(직업:12개),race(인종:아시아계,백인),capital-gain(자본이득),
# capital-loss(자본손실),hours-per-week(주당 근무시간),
# native-country(국가),income(소득)
#-------------------------------------------------------------

install.packages("arules") # AdultUCI 데이터 셋 이용을 위한 패키지 설치
library(arules)
data("AdultUCI")
str(AdultUCI) # 'data.frame':	48842 obs. of  15 variables:
names(AdultUCI)

# 데이터 샘플링 - 10,000개 관측치 선택 
set.seed(1234) # 메모리에 시드 값 적용
choice <- sample(1:nrow(AdultUCI), 10000)
choice
adult.df <-  AdultUCI[choice, ]  
str(adult.df) # ' # 'data.frame':	10000 obs. of  15 variables:

# 변수 추출 및 데이터 프레임 생성
# (1) 변수 추출
capital<- adult.df$`capital-gain`
hours<- adult.df$`hours-per-week`
education <- adult.df$`education-num`
race <- adult.df$race
age <- adult.df$age
income <- adult.df$income

# (2) 데이터프레임 생성
adult_df <- data.frame(capital=capital, age=age, race=race, hours=hours, education=education, income=income)
str(adult_df) # 'data.frame':	10000 obs. of  6 variables:

# formula 생성 - 자본이득(capital)에 영향을 미치는 변수 
formula <-  capital ~ income + education + hours + race + age

# ctree() : 분류모델 생성 및 예측
adult_ctree <- ctree(formula, data=adult_df)
adult_ctree # 가장 큰 영향을 미치는 변수 - income, education
# ※ 주의 : random으로 실행되기 때문에 실행결과는 다를 수 있다.

# 분류모델 플로팅
plot(adult_ctree)

# <해설> 자본이득(capital)에 가장 큰 영향을 미치는 변수는 income이고, 
# 두 번째는 education 변수이다. 

#--------------------------------------------------------------------
#<연습문제1> 분류모델 예측 
#--------------------------------------------------------------------
#<연습문제1>  classfication.csv 파일을 읽어서 total, price, period, variety 변수를
#    x변수로 response 변수를 y변수로 하여 의사결정 트리를 생성하시오.

# 변수설명  
# total : 총구매금액, price : 1회평균구매금액, period : 쇼핑시간, variety : 구매다양성

# 1) 데이터 가져오기(header 없음) 
result <- read.csv("C:/Rwork/Part-IV/classification.csv", header=FALSE) 

# 2) 테이블 모양 변경 패키지 설치
install.packages("reshape") 
library(reshape)

# 3) 변수명 지정
result <- rename(result, c(V1="total", V2="price", V3="period", V4="variety", V5="response")) 
View(result)
str(result) # 150 obs. of  5 variables:

#4) sample()함수 이용 학습데이터와 검정데이터 7:3 비율로 셈플링
idx <- sample(1:nrow(result), nrow(result)*0.7)
train <- result[idx, ]
test <- result[-idx, ]
dim(train); dim(test)
#5) formula 생성 : 종속변수 ~ 독립변수 
formula <- response ~ total+price+period+variety

#6) 분류모델 생성 : train 적용 - ctree() 함수 이용 
model <- ctree(formula, data = train)
model # 중요변수 : price
plot(model) # 모델 시각화 

#7) 분류모델 평가 : test 적용
p <- predict(model, test)

#8) 분류모델 성능 평가 -> 적중률 계산 
table(p, test$response)


