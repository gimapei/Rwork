ls
ls
ls()
num <- 10
string <- '이순'
string <- '이순신'
boolean <- TRUE
mode(num)
mode(string)
mode(boolean)
is.numeric(num)
is.character(num)
is.double(string)
mode(num)
class(num)
class(name2)
no <- c(1:5)
name <- c('a1','a2','a3','a4','a5')
no; name
emp <- data.frame(NO=no,NAME=name)
emp
mode(emp)
class(emp)
sum(10,20,30)
sum(5,4,3,2,NA)
sum(5,4,3,2,NA)
sum(5,4,3,2,NA, na.rm = T)
x <- c(1,2,3)
x <- c('1','2','3')
result <- x * 3
result <- x * 3  # error
xx <- as.numeric(x)
result <= xx * 3
result <- xx * 3
result <- xx * 3
result <- xx * 3
result
# 6) factor형 : 동일한 값을 범주로 갖는 Vector(하나의 변수에 1개 이상의 값을 가진변수, Array같은거)
gender <- c('m','f','m','m','f')
gender
man <- as.factor(gender)
man
plot(gender)
plot(gender) # error
man
plot(gender)
fgender <- as.factor(gender)
fgender
plot(fgender)
str(fgender)
class(fgender)
mode(fgender)
str(fgender)
fgender
Ogender <- factor(gender, levels=c('f','m'), labels=c('woman','man'))
Ogender
plot(Ogenger)
Ogender
Ogender <- factor(gender, levels=c('f','m'), labels=c('woman','man'))
plot(Ogenger)
plot(Ogender)
install.packages('stringr')
search()
library(string) # 패키지를 메모리에 올리는 명
library(stringr) # 패키지를 메모리에 올리는 명
search()
str_extract_all('홍길동34이순신35','[0-9]{2}')
str_extract_all('홍길동34이순신35','[a-zA-Z]{3}') #
str_extract_all('홍길동34이순신35','[가-히]{3}') #
str_extract_all('홍길동34이순신35','[가-히]{3}') # [1] "홍길동" "이순신"
data()
data(EuStockMarkets)
EuStockMarkets
EuStockMarkets[1:20]
str(EuStockMarkets)
hist(EuStockMarkets)
?sum
help(sum)
help(mean)  # sum(..., na.rm = FALSE)
mean(10,20,30)
x <- c(10,20,30)
mean(x)
getwd()
setwd('C:/Rwork/Part-I')
getwd() # [1] "C:/Rwork"
setwd('C:/Rwork')
filedata <- read.csv('c:/Rwork/Part-I/test.csv', header=T)
filedata
filedata <- read.csv('c:/Rwork/Part-I/test.csv', header=T) # 기본폴더에서 가져올때는 그냥 파일명만 명시해도 된다.
filedata
install.packages("arules") # association Rule
library(arules) #read.transactions()함수 제공
setwd("c:/Rwork/Part-IV")
setwd("c:/github/Rwork/Part-IV")
tran<- read.transactions("tran.txt", format="basket", sep=",")
tran
inspect(tran)
install.packages("lattice")
install.packages("lattice")
install.packages("lattice")
install.packages("lattice")
install.packages("lattice")
install.packages("lattice")
install.packages("lattice")
library(lattice)
install.packages("mlmRev")
library(mlmRev)
data(Chem97) # Chem97 데이터 셋 로드
str(Chem97) # 차원보기
head(Chem97,30)
histogram(~gcsescore, data=Chem97)
histogram(~gcsescore | score, data=Chem97)
histogram(~gcsescore | factor(score), data=Chem97)
# 2.densityplot : 밀도 그래프
# 형식) (~x축 | 조건, dataframe, groups=변수)
densityplot(~gcsescore | factor(score), data=Chem97,
groups = gender, plot.points=T, auto.key = T)
densityplot(~gcsescore | factor(score), data=Chem97,
groups = gender, plot.points=T, auto.key = T)
install.packages("ggplot2") # 패키지 설치
library(ggplot2)
### ggplot2 패키지 제공 데이터 셋
data(diamonds) # 데이터 셋 가져오기
data(mtcars)
data(mpg)
str(mpg) # map 데이터 셋 구조 보기
head(mpg) # map 데이터 셋 내용 보기
summary(mpg) # 요약 통계량
table(mpg$drv) # 구동방식 빈도수
qplot(hwy, data=mpg) # 세로막대 그래프
qplot(hwy, data=mpg, fill=drv) # fill 옵션 적용
qplot(hwy, data=mpg, fill=drv, binwidth=2) # binwidth 옵션 적용
qplot(hwy, data=mpg, fill=drv, facets=.~ drv, binwidth=2) # 열 단위 패널 생성
qplot(hwy, data=mpg, fill=drv, facets=drv~., binwidth=2) # 행 단위 패널 생성
qplot(displ, hwy, data=mpg)# mpg 데이터셋의 displ과 hwy변수 이용
# displ, hwy 변수 대상으로 drv변수값으로 색상 적용 산점도 그래프
qplot(displ, hwy, data=mpg, color=drv)
# (3) 색상, 크기, 모양 적용
### ggplot2 패키지 제공 데이터 셋
head(mtcars)
str(mtcars) # ggplot2에서 제공하는 데이터 셋
qplot(wt, mpg, data=mtcars, color=factor(carb)) # 색상 적용
qplot(wt, mpg, data=mtcars, size=qsec, color=factor(carb)) # 크기 적용
qplot(wt, mpg, data=mtcars, size=qsec, color=factor(carb), shape=factor(cyl))#모양 적용
mtcars$qsec
# (4) geom 옵션
### ggplot2 패키지 제공 데이터 셋
head(diamonds)
# geom="bar" -> clarity변수 대상 cut변수로 색 채우기
qplot(clarity, data=diamonds, fill=cut, geom="bar") # 레이아웃에 색 채우기
qplot(clarity, data=diamonds, colour=cut, geom="bar") # 테두리 색 적용
# geom="point"
qplot(wt, mpg, data=mtcars, size=qsec) # geom="point" 기본
qplot(wt, mpg, data=mtcars, size=qsec, geom="point")
# cyl 변수의 요인으로 point 크기 적용, carb 변수의 요인으로 포인트 색 적용
qplot(wt, mpg, data=mtcars, size=factor(cyl), color=factor(carb), geom="point")
# qsec변수로 포인트 크기 적용, cyl 변수의 요인으로 point 모양 적용
qplot(wt, mpg, data=mtcars, size=qsec, color=factor(carb), shape=factor(cyl), geom="point")
# geom="smooth"
qplot(wt, mpg, data=mtcars, geom=c("point", "smooth"))
qplot(wt, mpg, data=mtcars, color=factor(cyl), geom=c("point", "smooth"))
library(ggplot2)
install.packages("ggmap") # ‘ggmap’와 ‘ggplot2’(우선 설치) 관련 패키지
library(ggmap)
# 1. get_googlemap() 함수
#  지도위치정보를 이용하여 지도정보를 생성하고, 지도 이미지 그리기
#(e.g. "1600 pennsylvania avenue, washington dc" or "Baylor University")
# (1) 지도위치정보 가져오기
gc<- geocode("seoul, korea", source="google") # geolocation API 이용
center <- as.numeric(gc)
center # 위도,경도
#(2) 지도 정보 생성하기
map <- get_googlemap(center = center, language="ko-KR", color = "bw", scale = 2 )
# bw :  black-and-white - 흰색 바탕에 검은색 글자
# scale :  1, 2, or 4 (scale = 2 : 1280x1280 pixels)
# (3) 지도 이미지 그리기
ggmap(map, extent = 'device')
# extent : 지도가 그려질 크기를 지정하는 옵션
#  ("normal", "device", or "panel" (default))
# [실습] round(), get_googlemap()함수
#-------------------------------------------------
# (1) markers 데이터프레임 생성 -> round 적용
df <- round(data.frame( x = jitter(rep(-95.36, 25), amount = .3),
y = jitter(rep(29.76, 25), amount = .3) ), digits = 2)
# (2) 지도 위에 markers 적용
map <- get_googlemap('houston', markers = df, scale = 2)
ggmap(map, extent = 'device')
#-------------------------------------------------
# 2.  get_map함수
map <- get_map(location ="london", zoom=14, maptype='roadmap', scale=2)
# get_map("중심지역", 확대비율, 지도유형) : ggmap에서 제공하는 함수
ggmap(map, size=c(600,600), extent='device')
map <- get_map(location ="seoul", zoom=14, maptype='watercolor', scale=2)
ggmap(map, size=c(600,600), extent='device')
# zoom 차이
map <- get_map(location ="seoul", zoom=14, scale=2)
map <- get_map(location ="seoul", zoom=8, scale=2)
ggmap(map, size=c(600,600), extent='device')
# source 차이
map <- get_map(location = "texas", zoom = 6, source = "stamen")
# stamen : maptype='satellite' 지원 안됨
map <- get_map(location ="seoul", source = "osm", zoom=8, maptype='watercolor')
ggmap(map, size=c(600,600), extent='device')
map <- get_map(location = "seoul",zoom=14)
ggmap(map, size=c(600,600), extent='device')
# 3. 레이어 적용
# 실습 데이터-서울지역 4년제 대학교 위치 표시
university <- read.csv("C:/Rwork/Part-III/university.csv",header=T)
university # # 학교명","LAT","LON"
# (1)레이어1 : 정적 지도 생성
kor <- get_map("seoul", zoom=11, maptype = "watercolor")#roadmap
# maptype : roadmap, satellite, terrain, hybrid
# (2)레이어2 : 지도위에 포인트
ggmap(kor)+geom_point(data=university, aes(x=LON, y=LAT,color=factor(학교명)),size=3)
kor.map <- ggmap(kor)+geom_point(data=university, aes(x=LON, y=LAT,color=factor(학교명)),size=3)
# (3)레이어3 : 지도위에 텍스트 추가
kor.map + geom_text(data=university, aes(x=LON+0.01, y=LAT+0.01,label=학교명),size=5)
# LAT+0.01 : 텍스트 위치(포인트의 0.01 위쪽)
# geom_text : 텍스트 추가
# (4)지도 저장
# 넓이, 폭 적용 파일 저장
ggsave("C:/Rwork/output/university1.png",width=10.24,height=7.68)
# 밀도 적용 파일 저장
ggsave("C:/Rwork/output/university2.png",dpi=1000) # 9.21 x 7.68 in image
# 2015년도 06월 기준 대한민국 인구수
pop <- read.csv("C:/Rwork/Part-III/population201506.csv",header=T)
pop
region <- pop$지역명
lon <- pop$LON # 위도
lat <- pop$LAT # 경도
house <- pop$세대수
pop <- read.csv("C:/github/Rwork/Part-III/population201506.csv",header=T)
pop
region <- pop$지역명
lon <- pop$LON # 위도
lat <- pop$LAT # 경도
house <- pop$세대수
# 위도,경도,세대수 이용 데이터프레임 생성
df <- data.frame(region, lon,lat,house)
df
# 지도정보 생성
map1 <- get_map("daegu", zoom=7 ,  maptype='watercolor')
#map1 <- get_map("daegu", zoom=7 ,  maptype='roadmap')
# 레이어1: 지도 플로팅
map2 <- ggmap(map1)
map2
# 레이어2 : 포인트 추가
map2 + geom_point(aes(x=lon,y=lat,colour=house,size=house),data=df)
map3 <- map2 + geom_point(aes(x=lon,y=lat,colour=house,size=house),data=df)
# 레이어3 : 텍스트 추가
map3 + geom_text(data=df, aes(x=lon+0.01, y=lat+0.18,label=region),size=3)
# 크기, 넓이, 폭 적용 파일 저장
ggsave("C:/Rwork/output/population201506.png",scale=1,width=10.24,height=7.68)
#---------------------------------------------------
# <다양한 지도 유형>
# maptype='terrain'
map1 <- get_map("daegu", zoom=7 ,  maptype='terrain')
map2 <- ggmap(map1)
map3 <- map2 + geom_point(aes(x=lon,y=lat,colour=house,size=house),data=df)
map3 + geom_text(data=df, aes(x=lon+0.01, y=lat+0.18,label=region),size=3)
# maptype='satellite'
map1 <- get_map("daegu", zoom=7 ,  maptype='satellite')
map2 <- ggmap(map1)
map3 <- map2 + geom_point(aes(x=lon,y=lat,colour=house,size=house),data=df)
map3 + geom_text(data=df, aes(x=lon+0.01,y=lat+0.18,colour=region,label=region),size=3)
# maptype='roadmap'
map1 <- get_map("daegu", zoom=7 ,  maptype='roadmap')
map2 <- ggmap(map1)
map3 <- map2 + geom_point(aes(x=lon,y=lat,colour=house,size=house),data=df)
map3 + geom_text(data=df, aes(x=lon+0.01, y=lat+0.18,label=region),size=3)
# maptype='hybrid'
map1 <- get_map("jeonju", zoom=7,  maptype='hybrid')
map2 <- ggmap(map1)
map3 <- map2 + geom_point(aes(x=lon,y=lat,colour=house,size=house),data=df)
map3 + geom_text(data=df, aes(x=lon+0.01, y=lat+0.18,label=region),size=3)
map3 + geom_density2d()
# 밀도레이어 그래프 추가(geom_density2d)
install.packages("rJava")
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre1.8.0_77')
library(rJava) # 로딩
install.packages("rJava")
library(rJava) # 로딩
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre1.8.0_91')
library(rJava) # 로딩
install.packages("rJava")
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre1.8.0_91')
library(rJava) # 로딩
Sys.setenv(JAVA_HOME='C:\\Program Files (x86)\\Java\\jre1.8.0_91')
library(rJava) # 로딩
install.packages("rJava")
Sys.setenv(JAVA_HOME='C:\\Program Files (x86)\\Java\\jre1.8.0_91')
library(rJava) # 로딩
install.packages("rJava")
Sys.setenv(JAVA_HOME='C:\\Program Files (x86)\\Java\\jre1.8.0_91')
library(rJava) # 로딩
install.packages("rJava")
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jdk1.8.0_91')
library(rJava) # 로딩
install.packages(c("KoNLP", "tm", "wordcloud"))
library(KoNLP) # 한글 단어 처리 - rJava 영향
library(tm) # 텍스트 마이닝(전처리용)
library(wordcloud) # 단어 구름
extractNoun("안녕하세요. 저는 홍길동 입니다.")
facebook <- file("C:/github/Rwork/Part-II/facebook_bigdata.txt", encoding="UTF-8")
facebook_data <- readLines(facebook) # 줄 단위 데이터 생성
head(facebook_data) # 앞부분 6줄 보기 - 줄 단위 문장 확인
str(facebook_data) # chr [1:76]
# 2. Corpus : 텍스트 데이터 -> 자료집(documents) 생성(tm 패키지 제공)
facebook_corpus <- Corpus(VectorSource(facebook_data))
facebook_corpus
# 76개 자료집 보기 - 포함된 문자 수 제공
inspect(facebook_corpus)
# 3. 분석 대상 자료집을 대상으로 NA 처리(공백)
facebook_corpus[is.na(facebook_corpus)]   <- " "
facebook_corpus
# 4. 세종 사전 사용 및 단어 추가
useSejongDic() # 세종 사전 불러오기
# 세종 사전에 없는 단어 추가
mergeUserDic(data.frame(c("R 프로그래밍","페이스북","소셜네트워크"), c("ncn")))
# ncn -명사지시코드
# 5. 단어추출 사용자 함수 정의
# (1) 사용자 정의 함수 실행 순서 : 문자변환 -> 명사 단어추출 -> 공백으로 합침
exNouns <- function(x) {
paste(extractNoun(as.character(x)), collapse=" ")
}
# (2) exNouns 함수 이용 단어 추출
# 형식) sapply(적용 데이터, 적용함수)
facebook_nouns <- sapply(facebook_corpus, exNouns)
# (3) 단어 추출 결과
#class(facebook_nouns) # [1] "character" -> Vector 타입
facebook_nouns[1] # 단어만 추출된 첫 줄 보기
# 6. 데이터 전처리
# (1) 추출된 단어 이용하여 자료집 생성
myCorputfacebook <- Corpus(VectorSource(facebook_nouns))
# (2) 데이터 전처리
myCorputfacebook <- tm_map(myCorputfacebook, removePunctuation) # 문장부호 제거
myCorputfacebook <- tm_map(myCorputfacebook, removeNumbers) # 수치 제거
myCorputfacebook <- tm_map(myCorputfacebook, tolower) # 소문자 변경
# (3) 전처리 결과 확인
myCorputfacebook <-tm_map(myCorputfacebook, removeWords, stopwords('english')) # 불용어제거
inspect(myCorputfacebook[1:5]) # 데이터 전처리 결과 확인
stopwords('english')
# 7. 단어 선별(단어 길이 2개 이상)
# (1) 자료집 -> 일반문서 변경
myCorputfacebook_txt <- tm_map(myCorputfacebook, PlainTextDocument)
# (2) TermDocumentMatrix() : 단어 선별(단어길이 2개 이상인 단어 선별 -> matrix 변경)
myCorputfacebook_txt <- TermDocumentMatrix(myCorputfacebook_txt, control=list(wordLengths=c(2,Inf)))
myCorputfacebook_txt
# (3) matrix -> data.frame 변경(빈도분석을 위해서)
myTermfacebook.df <- as.data.frame(as.matrix(myCorputfacebook_txt))
dim(myTermfacebook.df) # [1] 876  76
# 8. 단어 빈도수 구하기(행 단위 합계 -> 내림차순 정렬)
wordResult <- sort(rowSums(myTermfacebook.df), decreasing=TRUE) # 빈도수로 내림차순 정렬
wordResult[1:10]
#빅데이터     사용     분석     처리     수집
#      21       20       19       16       15
# 9. wordcloud 생성 (디자인 적용전)
wordcloud(c("한국", "일본"), c(10,5))
myName <- names(wordResult) # 단어 이름 생성 -> 빈도수의 이름
wordcloud(myName, wordResult) # 단어구름 적용
#---------------<불필요한 단어 제거 시작 :  6 ~ 9단계 수행>-------------------
# 6. 데이터 전처리 - "사용", "하기" 단어 제거
myCorputfacebook <- tm_map(myCorputfacebook, removePunctuation) # 문장부호 제거
myCorputfacebook <- tm_map(myCorputfacebook, removeNumbers) # 수치 제거
myCorputfacebook <- tm_map(myCorputfacebook, tolower) # 소문자 변경
myStopwords = c(stopwords('english'), "사용", "하기");
myCorputfacebook = tm_map(myCorputfacebook, removeWords, myStopwords);
# 7. 단어 선별(단어 길이 2개 이상)
myCorputfacebook_txt <- tm_map(myCorputfacebook, PlainTextDocument)
myCorputfacebook_txt <- TermDocumentMatrix(myCorputfacebook_txt, control=list(wordLengths=c(2,Inf)))
myTermfacebook.df <- as.data.frame(as.matrix(myCorputfacebook_txt))
dim(myTermfacebook.df) # [1] 876  76
# 8. 단어 빈도수 구하기
wordResult <- sort(rowSums(myTermfacebook.df), decreasing=TRUE) # 빈도수로 내림차순 정렬
wordResult[1:10]
#빅데이터     분석     처리     수집     결과
#21       19       16       15       13
# 9. 단어 구름(wordcloud) 생성  생성 - 디자인 적용 전
myName <- names(wordResult) # 단어 이름 추출(빈도수 이름)
wordcloud(myName, wordResult) # 단어구름 시각화
#myName
#------------------<불필요한 단어 제거 종료 >-----------------------
# 10. 단어구름에 디자인 적용(빈도수, 색상, 랜덤, 회전 등)
# (1) 단어이름과 빈도수로 data.frame 생성
word.df <- data.frame(word=myName, freq=wordResult)
str(word.df) # word, freq 변수
# (2) 단어 색상과 글꼴 지정
pal <- brewer.pal(12,"Paired") # 12가지 색상 pal <- brewer.pal(9,"Set1") # Set1~ Set3
# 폰트 설정세팅 : "맑은 고딕", "서울남산체 B"
windowsFonts(malgun=windowsFont("맑은 고딕"))  #windows
# (3) 단어 구름 시각화 - 별도의 창에 색상, 빈도수, 글꼴, 회전 등의 속성을 적용하여
x11( ) # 별도의 창을 띄우는 함수
wordcloud(word.df$word, word.df$freq,
scale=c(5,1), min.freq=3, random.order=F,
rot.per=.1, colors=pal, family="malgun")
#wordcloud(단어, 빈도수, 5:1비율 크기,최소빈도수,랜덤순서,랜덤색상, 회전비율, 색상(파렛트),컬러,글꼴 )
topWord <- head(sort(wordResult, decreasing=T), 10) # 상위 10개 토픽추출
# (2) 파일 차트 생성
pie(topWord, col=rainbow(10), radius=1) # 파이 차트-무지개색, 원크기
# (3) 빈도수 백분율 적용
pct <- round(topWord/sum(topWord)*100, 1) # 백분율
names(topWord)
# (4) 단어와 백분율 하나로 합친다.
lab <- paste(names(topWord), "\n", pct, "%")
# (5) 파이차트에 단어와 백분율을 레이블로 적용
pie(topWord, main="SNS 빅데이터 관련 토픽분석", col=rainbow(10), cex=0.8, labels=lab)
###################################################
# 단계2 - 연관어 분석(단어와 단어 사이 연관성 분석)
#   - 시각화 : 연관어 네트워크 시각화, 근접중심성 시각화
###################################################
# 한글 처리를 위한 패키지 설치
install.packages("rJava")
install.packages("rJava")
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre1.8.0_60')
library(rJava) # 아래와 같은 Error 발생 시 Sys.setenv()함수로 java 경로 지정
install.packages("KoNLP")
install.packages("KoNLP")
library(KoNLP) # rJava 라이브러리가 필요함
library(stringr)
GDP_ranking <- read.csv('http://databank.worldbank.org/data/download/GDP.csv')
GDP_ranking
# 분포 확인
head(GDP_ranking)
tail(GDP_ranking)
# (2) 데이터 전처리
GDP_ranking20 <- head(GDP_ranking, 20)
# 필요한 행과 칼럼 제거
GDP_ranking20 <- GDP_ranking[-c(1:4),c(1,2,4,5)]
GDP_ranking20
# 칼럼 수정
names(GDP_ranking20)<- c("CODE","Rank","Nation","GDP")
head(GDP_ranking20,15)
# GDP 칼럼 전처리(문자열 -> 숫자)
Nation <- GDP_ranking20$Nation
GDP <- GDP_ranking20$GDP
GDP
# 콤마 제거
GDP <- str_replace_all(GDP,",","")
# 숫자 변경
GDP <- as.numeric(GDP)
length(GDP) # 326
# GDP 순위를 보여주는 차트
GDP <- head(GDP, 15)
barplot(GDP, main = '세계 상위 15 GDP 순위',
col=rainbow(15), xlab='국가')
# y축 이름 수정
GDP <- GDP / 1000
GDP
max(GDP); min(GDP)
barplot(GDP, main = '세계 상위 15 GDP 순위',
col=rainbow(15), xlab='국가',
ylab='단위:달러', ylim=c(0, 20000))
# 5) 웹문서 가져오기
install.packages("XML")
library(XML) # <table> <tr> <td> <th>
# 미국의 각 주별 1인당 소득자료
info.url <- "http://www.infoplease.com/ipa/A0104652.html"
# readHTMLTable() 함수 역할 - <table>,<tr>,<td> 태그 이용
info.df<-readHTMLTable(info.url, header=T, which=1, stringsAsFactors=F)
# header=T : 컬럼명 있음, which=1 : 첫번째, stringsAsFactors 문자는 범주(값의 목록)처리 안함
info.df
source('C:/GitHub/Rwork/R-script/강사님수업자료/chap03_DataIO.R', encoding = 'UTF-8', echo=TRUE)
info.url <- "http://score.sports.media.daum.net/record/baseball/kbo/trnk.daum"
# readHTMLTable() 함수 역할 - <table>,<tr>,<td> 태그 이용
info.df<-readHTMLTable(info.url, header=T, which=1, stringsAsFactors=F)
# header=T : 컬럼명 있음, which=1 : 첫번째, stringsAsFactors 문자는 범주(값의 목록)처리 안함
info.df
# 레코드 수 변경 확인 <- update
info.df<-info.df[1:53,] # NA 레코드 제거(54행 제거)
info.df<-info.df[c(-2,-28),] # $가 있는 행 제거
# 컬럼명 변경
info.df<-info.df[c(-1,-2),] # 1,2행 제거
# 컬럼명 추가
names(info.df) <- c("State",1980,1990,1995,2000,2003,2006,2009,2012)
head(info.df)
# 2009, 2012년 주별 합계를 구하시오.
State <- info.df$State
y2009 <- info.df$`2009`
y2012 <- info.df$`2012`
State; y2009; y2012
library(stringr)
y2009 <- str_replace_all(y2009,',','')
y2009 <- as.numeric(y2009)
y2012 <- str_replace_all(y2012,',','')
y2012 <- as.numeric(y2012)
df <- data.frame(y2009=y2009, y2012=y2012)
df
sum <- apply(df, 1, sum)
df2 <- data.frame(State,y2009,y2012,sum)
head(df2)
info.url <- "http://score.sports.media.daum.net/record/baseball/kbo/trnk.daum"
# readHTMLTable() 함수 역할 - <table>,<tr>,<td> 태그 이용
info.df<-readHTMLTable(info.url, header=T, which=1, stringsAsFactors=F)
# header=T : 컬럼명 있음, which=1 : 첫번째, stringsAsFactors 문자는 범주(값의 목록)처리 안함
info.df
head(inf.df)
head(inf.df,5)
head(info.df,5)
info.df<-info.df[c(-1,-1),] # 1,2행 제거
head(info.df,5)
info.df<-info.df[c(-1,-1),] # 1,2행 제거
head(info.df,5)
info.df<-info.df[c(-1,-2),] # 1,2행 제거
head(info.df,5)
1980,1990,1995,2000,2003,2006,2009,2012
names(info.df) <- c("순위","팀명")
head(info.df)
names(info.df) <- c("순위","팀명","경기수","승","무","패","승률","승차","최근","상대팀","스코어")
head(info.df)
names(info.df) <- c("순위","팀명","경기수","승","무","패","승률","승차","최근","상대팀","스코어")
names(info.df) <- c("순위","팀명","경기수","승","무","패","승률","승차","최근","상대팀","스코어")
head(info.df)
